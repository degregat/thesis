{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation \n",
    "Data can be dowloaded from http://www.trialsjournal.com/content/supplementary/1745-6215-12-101-s1.csv\n",
    "The article and description is at http://www.trialsjournal.com/content/12/1/101/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#stroke =  pd.read_csv(\"data/IST_data.csv\", true_values='Y', false_values='N', na_values='U', skipinitialspace=True,low_memory=False)\n",
    "#stroke.dropna(inplace=True,subset=['CMPLASP'])\n",
    "#stroke.dropna(inplace=True,subset=['CMPLHEP'])\n",
    "\n",
    "\n",
    "stroke_processed = pd.read_csv('data/stroke.csv', low_memory=False) #this mixed type warning if i dont include the low memory, why exactly?\n",
    "\n",
    "class IST():\n",
    "    def __init__(self, drug='RXHEP'):\n",
    "        outcome=\"Alive14D\"\n",
    "        stroke = stroke_processed[np.isfinite(stroke_processed[outcome])]\n",
    "        self.arm_id = list(stroke_processed[drug].unique())\n",
    "        random.shuffle(self.arm_id) #assign random index to each arm, so bugs that prefer a index cant help\n",
    "        self.arms = [stroke[stroke[drug] == arm][['actual'+drug,outcome]].values for arm in self.arm_id]\n",
    "        self.arm_samples = [len(a) for a in self.arms]\n",
    "    def draw_subject(self):\n",
    "        r= [ random.randint(0,h) for h in self.arm_samples]\n",
    "        return [(self.arm_id.index(self.arms[i][rr][0]),self.arms[i][rr][1]) for i,rr in enumerate(r)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=5, micro=1, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numpy import random\n",
    "\n",
    "from pymc import rbeta\n",
    "\n",
    "import scikits.bootstrap as boot\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline  \n",
    "\n",
    "import math\n",
    "from __future__ import division\n",
    "import pprint\n",
    "\n",
    "import numba # we need the very latest numba to do this with jit classes, TODO later\n",
    "import Cython\n",
    "import sys\n",
    "print(sys.version_info)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#from collections import deque "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#utility functions\n",
    "\n",
    "def ci(v):\n",
    "    cie= boot.ci( v, np.mean )\n",
    "    return cie[0],cie[1]\n",
    "\n",
    "def display_results(r):\n",
    "    display(r.groupby([\"drug\",\"base bandit\"]).agg([ np.mean, np.median, np.min, np.max, np.std, ci]))\n",
    "    display(r.groupby([\"drug\",\"high estimator\"]).agg([np.mean,np.median,np.min, np.max, np.std, ci]))\n",
    "    display(r.groupby([\"drug\",\"high estimator\",\"base bandit\"]).agg([ np.mean,np.median, np.min, np.max, np.std, ci]))\n",
    "    display(r.groupby([\"high estimator\",\"base bandit\"]).agg([ np.mean,np.median, np.min, np.max, np.std, ci]))\n",
    "    sns.plt.show()\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def potentials_to_probs(x):\n",
    "  return sigmoid(x)/sigmoid(x).sum()\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def online_mean(old,v,n):\n",
    "    return ((n - 1) / float(n)) * old + (1 / float(n)) * v\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def decay_avg(old,v,n, g=0):\n",
    "    return ((n - (1+g)) / float(n)) * old + ((1+g) / float(n)) * v\n",
    "    # tune g online to achieve good prediction of conditional reward given chosen action\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def stochastic_argmax(x):\n",
    "    \"\"\"returns the index of a max value, if there are multiple, picks one uniformly at random\"\"\"\n",
    "    #  cleaner but cant numba: return np.random.choice(np.where( x >= x[x.argmax()] )[0])\n",
    "    candidates = np.where( x >= x[x.argmax()] )[0]\n",
    "    return ( candidates[np.random.randint(0,len(candidates))])\n",
    "\n",
    "#much faster than np.random.choice ?\n",
    "@numba.jit(nopython=True)\n",
    "def categorical_draw(probs):\n",
    "  z = random.random()\n",
    "  cum_prob = 0.0\n",
    "  for i in range(probs.shape[0]):\n",
    "    cum_prob += probs[i]\n",
    "    if cum_prob > z: return i\n",
    "  return probs.shape[0] - 1\n",
    "\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def beta(svec,fvec):\n",
    "    v = np.zeros(svec.shape[0])\n",
    "    for i in range(svec.shape[0]):\n",
    "        v[i] = random.beta(svec[i],fvec[i])\n",
    "    return v\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Bandit(object):\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.values = np.ones(n_arms,dtype=np.float64)\n",
    "        self.counts = np.ones(n_arms, dtype=np.float64)\n",
    "    def update_reward(self, chosen_arm, reward, probability=1):\n",
    "        #reward= 1/probability\n",
    "        self.counts[chosen_arm] += 1\n",
    "        self.values[chosen_arm] = online_mean(self.values[chosen_arm],reward,self.counts[chosen_arm])\n",
    "\n",
    "\n",
    "class RandomBandit(Bandit):\n",
    "    def select_arm(self):\n",
    "        return int(random.random()*self.n_arms)\n",
    "\n",
    "class ThompsonBeta():\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.sucess = np.zeros(n_arms,dtype=np.float64)\n",
    "        self.failures = np.zeros(n_arms, dtype=np.float64)\n",
    "    def update_reward(self, chosen_arm, reward, probability=1):\n",
    "        if reward == 1:self.sucess[chosen_arm] += 1/probability \n",
    "        else: self.failures[chosen_arm] += 1/probability\n",
    "    def select_arm(self):\n",
    "        return stochastic_argmax( beta(1 + self.sucess, 1 + self.failures) )\n",
    "    def get_probs(self):\n",
    "        return (1 + self.sucess )/( 2 + self.failures  + self.sucess )\n",
    "    \n",
    "class Softmax(Bandit):\n",
    "    def select_arm(self):\n",
    "        t = sum(self.counts) + 1\n",
    "        temperature = 1 / math.log(t + 0.0000001) # or 0.1\n",
    "        mv = np.max(self.values)\n",
    "        z =  np.sum(np.exp((self.values-mv) / temperature))\n",
    "        probs = np.exp((self.values-mv) / temperature) / z\n",
    "        return categorical_draw(probs)\n",
    "\n",
    "class EpsilonGreedy(Bandit):\n",
    "    def select_arm(self):\n",
    "        t = sum(self.counts) + 1\n",
    "        epsilon = 1 / math.log(t + 0.0000001) # or jus 0.1\n",
    "        if random.random() > epsilon: return stochastic_argmax(self.values)\n",
    "        else: return random.randint(self.n_arms)\n",
    "\n",
    "\n",
    "class UCB1(Bandit):\n",
    "    def select_arm(self):\n",
    "        if np.min(self.counts) == 0:\n",
    "            chosen_arm = np.argmin(self.counts)\n",
    "        else:\n",
    "            ucb_values = np.zeros(self.n_arms)\n",
    "            total_counts = np.sum(self.counts)\n",
    "            for arm in range(self.n_arms):\n",
    "                ucb_values[arm] = self.values[arm] + math.sqrt((2 * np.log(total_counts)) / self.counts[arm])\n",
    "            chosen_arm = stochastic_argmax(ucb_values)\n",
    "        return chosen_arm\n",
    "\n",
    "class Exp3V():\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.weights = np.zeros(n_arms, dtype=np.float64)\n",
    "        self.probs = np.zeros(n_arms, dtype=np.float64)\n",
    "    def select_arm(self):\n",
    "        return np.exp(categorical_draw(self.probs))\n",
    "    def get_probs(self):\n",
    "        return np.exp(self.probs)\n",
    "    def update_reward(self, chosen_arm, reward, probability=1):\n",
    "        gamma=0.0085 #0.0085 seems to have come from the bound optimized parameters, but how?\n",
    "        logreward = log(reward) - log(probability)\n",
    "        self.weights[chosen_arm] = self.weights[chosen_arm] + np.log(gamma) + (logreward - self.probs[chosen_arm])\n",
    "        self.probs = self.weights - logsumexp(self.weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Build Compliance Aware Bandits and baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_derivative_bandits(base_algos):\n",
    "    resulting_algos=[]\n",
    "    for b in base_algos:\n",
    "        class chosen(b):\n",
    "            def update(self, chosen, actual,reward): \n",
    "                self.update_reward(chosen,reward)\n",
    "        resulting_algos.append(chosen)\n",
    "\n",
    "        class actual(b):\n",
    "            def update(self, chosen, actual,reward): \n",
    "                self.update_reward(actual,reward)\n",
    "        resulting_algos.append(actual)\n",
    "\n",
    "        class comply_only(b):\n",
    "            def update(self, chosen_arm, actual_arm,reward): \n",
    "                if chosen_arm == actual_arm:\n",
    "                    self.update_reward( actual_arm,reward)\n",
    "        resulting_algos.append(comply_only)\n",
    "\n",
    "        class DoubleBanditRecycle():\n",
    "            def __init__(self, n_arms, base_algo=b,higher_algo=Exp3V):#b\n",
    "                self.n_arms = n_arms\n",
    "                self.low_bandits = [base_algo(n_arms),base_algo(n_arms),base_algo(n_arms)]\n",
    "                self.high_bandit = higher_algo(len(self.low_bandits)) \n",
    "                self.prev_high_chosen = []\n",
    "                self.unused_samples = [[] for i in range(n_arms)]\n",
    "\n",
    "            def update(self, chosen, actual, reward):\n",
    "                if self.prev_high_chosen[0] == 0: self.low_bandits[0].update_reward(chosen,reward,self.high_bandit.get_probs()[0]) # asimptotically good no matter what\n",
    "                else: self.unused_samples[chosen].append(reward)\n",
    "                self.low_bandits[1].update_reward(actual,reward) # finite sample better when noncmopliance indepedent of rewards\n",
    "                if chosen==actual: self.low_bandits[2].update_reward(chosen,reward)# good when noncompliers have different distribution of rewards than compliers\n",
    "                self.high_bandit.update_reward(self.prev_high_chosen[0],reward)\n",
    "                    \n",
    "            def select_arm(self):\n",
    "                choices = [self.low_bandits[i].select_arm() for i in range(len(self.low_bandits))]\n",
    "                self.prev_high_chosen =[self.high_bandit.select_arm()] # [i for i, v in enumerate(choices) if v == chosen]\n",
    "                if self.prev_high_chosen[0] != 0: #it is not normally when chosen would play\n",
    "                    if min([len(a) for a in self.unused_samples]) > 0: #but we can still give it feedback, becuase we chose this before, so know how it woudl work out (IID)\n",
    "                        reward= self.unused_samples[choices[0]].pop()\n",
    "                        self.low_bandits[0].update_reward(choices[0],reward, self.high_bandit.get_probs()[0])\n",
    "                return  choices[self.prev_high_chosen[0]]\n",
    "        resulting_algos.append(DoubleBanditRecycle)\n",
    "\n",
    "     \n",
    "        \n",
    "        class DoubleBanditsThompsonBounded():\n",
    "            def __init__(self, n_arms, base_algo=b,higher_algo=ThompsonBeta):#b\n",
    "                self.n_arms = n_arms\n",
    "                self.chosen_bounding = ThompsonBeta(n_arms)\n",
    "                self.low_bandits = [base_algo(n_arms),base_algo(n_arms),base_algo(n_arms)]#,base_algo(n_arms)]\n",
    "                self.high_bandit = higher_algo(len(self.low_bandits)) #or 4 or 6 (+LATE?) or f(k beyond 2 arms, how mani bits?) ?\n",
    "                self.prev_high_chosen = [] \n",
    "                self.prev_bound_used = True\n",
    "                self.unused_samples = [[] for i in range(n_arms)]\n",
    "\n",
    "            def update(self, chosen, actual, reward):\n",
    "                if self.prev_bound_used:\n",
    "                    self.chosen_bounding.update_reward(chosen,reward, sum(self.chosen_bounding.get_probs()**2) )\n",
    "                else: self.unused_samples[chosen].append(reward)\n",
    "                self.low_bandits[0].update_reward(chosen,reward) # asimptotically good no matter what\n",
    "                self.low_bandits[1].update_reward(actual,reward) # finite sample better when noncmopliance indepedent of rewards\n",
    "                if chosen==actual: self.low_bandits[2].update_reward(chosen,reward)# good when noncompliers have different distribution of rewards than compliers\n",
    "                for v in self.prev_high_chosen: self.high_bandit.update_reward(v,reward)\n",
    "\n",
    "            def select_arm(self): #aethetic of the while\n",
    "                choices = [self.low_bandits[i].select_arm() for i in range(len(self.low_bandits))]\n",
    "                if (self.chosen_bounding.select_arm() == self.chosen_bounding.select_arm()):\n",
    "                    bound_chose = self.chosen_bounding.select_arm()\n",
    "                    if len(self.unused_samples[bound_chose]) - 1/self.n_arms > 0:\n",
    "                        # use that to feed and continue since we can preserve the bound without taking away from doublebandit\n",
    "                        reward= self.unused_samples[bound_chose].pop()\n",
    "                        self.chosen_bounding.update_reward(bound_chose,reward, sum(self.chosen_bounding.get_probs()**2) )    \n",
    "                    else:\n",
    "                        self.prev_bound_used = True\n",
    "                        self.prev_high_chosen = []#[i for i, v in enumerate(choices) if v == bound_chose]\n",
    "                        return bound_chose #doesnt matter whic one we use, by construction, so we use 0\n",
    "                self.prev_bound_used = False\n",
    "                high_chosen =self.high_bandit.select_arm() \n",
    "                chosen = choices[high_chosen] \n",
    "                self.prev_high_chosen = [high_chosen]#[i for i, v in enumerate(choices) if v == chosen]\n",
    "                return chosen\n",
    "   \n",
    "        resulting_algos.append(DoubleBanditsThompsonBounded)\n",
    "    return resulting_algos\n",
    "\n",
    "all_algos=make_derivative_bandits([Exp3V,EpsilonGreedy,UCB1,ThompsonBeta])\n",
    "base_name = [\"Exp3V\", \"EpsilonGreedy\",\"UCB1\",\"ThompsonBeta\"]\n",
    "high_name = [\"chosen\",\"actual\",\"comply\",\"HB\",\"TB\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Simulation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sim(drug, DGP=IST ,nsim=10, T=10001, steps=10):\n",
    "    columns=['base bandit','high estimator',\"surplus\",'drug','t']\n",
    "    results = pd.DataFrame(np.zeros((nsim*steps*len(all_algos), len(columns))), columns=columns) #hardcodes 20 algos*baselines, nasty\n",
    "    counter=0\n",
    "    for s in range(nsim):\n",
    "        dgp=DGP(drug)\n",
    "        k = len(dgp.draw_subject())\n",
    "        rewards=np.zeros(len(all_algos))\n",
    "        bandit_instances = [b(k) for b in all_algos]\n",
    "        mean_rewards = 0\n",
    "        for t in range(T):\n",
    "            r = dgp.draw_subject()\n",
    "            mean_rewards += np.sum([v/k for a,v in r])\n",
    "            for i,a in enumerate(bandit_instances): \n",
    "                chosen = int(a.select_arm())\n",
    "                actual,reward = r[chosen]\n",
    "                a.update(chosen,actual,reward)\n",
    "                rewards[i]+= reward\n",
    "            if (t%int(T/steps) == 0) and (t>0):\n",
    "                for i in range(len(all_algos)):\n",
    "                    results.iloc[counter] = pd.Series( {\n",
    "                                        'base bandit':base_name[i//len(high_name)] , \n",
    "                                         'high estimator':high_name[i%len(high_name)],\n",
    "                                         'surplus':rewards[i] - mean_rewards ,\n",
    "                                         'drug':drug,\n",
    "                                         't':t})\n",
    "                    counter+=1\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bandit_instances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7657896b7082>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandit_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bandit_instances' is not defined"
     ]
    }
   ],
   "source": [
    "len(bandit_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/nikete/anaconda/envs/3.5/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/nikete/anaconda/envs/3.5/lib/python3.5/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-18-2537bbb189d0>\", line 18, in sim\n    actual,reward = r[chosen]\nIndexError: list index out of range\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-289213c7975d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base bandit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'high estimator'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"surplus\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'drug'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#how many cores do we wan to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpartial_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpartial_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nikete/anaconda/envs/3.5/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nikete/anaconda/envs/3.5/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "inputs = [\"RXASP\",\"RXHEP\"]*1 #number of replications 1/2 cores\n",
    "results = pd.DataFrame(columns=['base bandit','high estimator',\"surplus\",'drug','t'])\n",
    "with Pool(2) as p: #how many cores do we wan to use\n",
    "    partial_results=(p.map(sim, inputs))\n",
    "for p in partial_results:\n",
    "    results = pd.concat([p,results] )\n",
    "display_results(results.loc[results['t'] == 10000].drop('t',1))\n",
    "\n",
    "results.to_csv('100krunfig1.csv')\n",
    "\n",
    "g = sns.factorplot(x='t', y=\"surplus\", hue=\"high estimator\", data=results,\n",
    "                   size=6, palette=\"muted\", row=\"base bandit\") #\n",
    "g.despine(left=True)\n",
    "g.set_ylabels(\"lives saved\")\n",
    "g.savefig(\"Fig1.png\")\n",
    "\n",
    "\n",
    "g = sns.factorplot(x='t', y=\"surplus\", hue=\"high estimator\", data=results,\n",
    "                   size=6, palette=\"muted\", row=\"drug\",col=\"base bandit\") #\n",
    "g.despine(left=True)\n",
    "g.set_ylabels(\"lives saved\")\n",
    "g.savefig(\"by_drug_appendix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2(Linear regret; harmful treatment).Suppose there are two sub-populations: the first consists ofrich,\n",
    "#healthy patients who always take the treatment. \n",
    "#Thesecond consists of poor,less healthy patients who only takethe treatment if prescribed. \n",
    "# Finally, suppose the treatmentreduceswellbeing by0:25on some metric.\n",
    "class ExampleTwo():\n",
    "    def __init__(self,foo):\n",
    "        self.n_arms = 2\n",
    "    def draw_subject(self):\n",
    "        if random.random() > 0.5: user_type = \"rich\"\n",
    "        else: user_type = \"poor\"\n",
    "\n",
    "        if user_type == \"rich\":\n",
    "             # if they didnt take it they would all do well, but they all take it so only 0.75 chance \n",
    "            outcome = random.binomial(1,0.75)\n",
    "            r=[(1, outcome) for i in range(self.n_arms)] \n",
    "        else: #poor, they only take them if told, which brings them down from 0.5 chance to 0.75  \n",
    "            reward = [random.binomial(1,0.5),random.binomial(1,0.25)] \n",
    "            r= [(i, reward[i]) for i in range(self.n_arms)]\n",
    "        return r\n",
    "    \n",
    "example2 = sim( nsim=100, T=10001, DGP=ExampleTwo , drug=\"example 2\")\n",
    "display_results(example2.loc[example2['t'] == 10000].drop('t',1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "g = sns.factorplot(x='t', y=\"surplus\", hue=\"high estimator\", data=example2,\n",
    "                   size=6, palette=\"muted\", col=\"base bandit\") #\n",
    "g.despine(left=True)\n",
    "g.set_ylabels(\"lives saved\")\n",
    "g.savefig(\"fig0.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NoncomplianceForBestArm():\n",
    "    def __init__(self,foo ):\n",
    "        n_arms=2\n",
    "        self.arm_value = 0.5+0.25*np.random.random(n_arms)\n",
    "        self.n_arms = n_arms\n",
    "    def draw_subject(self):\n",
    "        prefered_arm = stochastic_argmax(self.arm_value)\n",
    "        prefered_reward = random.binomial(1,self.arm_value[prefered_arm])\n",
    "        r = []\n",
    "        for i in range(self.n_arms):\n",
    "            if self.arm_value[i] / self.arm_value[prefered_arm] < random.random(): #informative noncompliance\n",
    "                r.append((prefered_arm,prefered_reward))\n",
    "            else:  #compliers \n",
    "                r.append((i,  random.binomial(1,self.arm_value[i])))\n",
    "        return r\n",
    "\n",
    "example3= sim( nsim=100, T=10001, DGP=NoncomplianceForBestArm , drug=\"Better arm\")\n",
    "display_results(example3.loc[example3['t'] == 10000].drop('t',1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "g = sns.factorplot(x='t', y=\"surplus\", hue=\"high estimator\", data=example3,\n",
    "                   size=6, palette=\"muted\", col=\"base bandit\") #\n",
    "g.despine(left=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#always or never takers. current simulation model is not rich enough for defiers, todo?\n",
    "class IndependentNoncomplianceAndRewards():\n",
    "    def __init__(self,foo):\n",
    "        n_arms=2\n",
    "        self.arm_value = 0.9+0.1*np.random.random(int(n_arms))\n",
    "        # todo add effect_magnitude=1\n",
    "        self.n_arms = n_arms\n",
    "    def draw_subject(self):\n",
    "        if random.random()<0.9: #compliers \n",
    "            r=[(i, random.binomial(1,self.arm_value[i])) for i in range(self.n_arms)]\n",
    "        else:   #always takers\n",
    "            actual = categorical_draw(self.arm_value)\n",
    "            reward = random.binomial(1,self.arm_value[actual])\n",
    "            r= [(actual, reward) for i in range(self.n_arms)]\n",
    "        return r\n",
    "\n",
    "    \n",
    "example4= sim( nsim=100, T=10001, DGP=IndependentNoncomplianceAndRewards , drug=\"example\")\n",
    "display_results(example4.loc[example4['t'] == 10000].drop('t',1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='t', y=\"surplus\", hue=\"high estimator\", data=example4,\n",
    "                   size=6, palette=\"muted\", col=\"base bandit\") #\n",
    "g.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#REMEMBER TO SET EXP3V appropiately before running this\n",
    "\n",
    "class IndependentNoncomplianceAndRewards():\n",
    "    def __init__(self,foo):\n",
    "        n_arms=2\n",
    "        self.arm_value = np.random.random(int(n_arms))\n",
    "        # todo add effect_magnitude=1\n",
    "        self.n_arms = n_arms\n",
    "    def draw_subject(self):\n",
    "        if random.random()>0.5: #compliers \n",
    "            r=[(i, random.binomial(1,self.arm_value[i])) for i in range(self.n_arms)]\n",
    "        else:   #always takers\n",
    "            actual = categorical_draw(self.arm_value)\n",
    "            reward = random.binomial(1,self.arm_value[actual])\n",
    "            r= [(actual, reward) for i in range(self.n_arms)]\n",
    "        return r\n",
    "\n",
    "\n",
    "    \n",
    "example5= sim( nsim=1000, T=12, DGP=IndependentNoncomplianceAndRewards , drug=\"example\")\n",
    "display_results(example5.loc[example5['t'] == 11].drop('t',1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(x='t', y=\"surplus\", hue=\"high estimator\", data=example5,\n",
    "                   size=6, palette=\"muted\", col=\"base bandit\") #\n",
    "g.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
